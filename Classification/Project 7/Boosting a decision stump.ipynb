{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Govind\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv(r\"D:\\Classification\\Project 7\\data\\lending-club-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>collections_12_mths_zero</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>final_d</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_record_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.14350</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.25955</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27585</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075269</td>\n",
       "      <td>1311441</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90</td>\n",
       "      <td>156.46</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.21533</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000             4975   36 months   \n",
       "1  1077430    1314167       2500         2500             2500   60 months   \n",
       "2  1077175    1313524       2400         2400             2400   36 months   \n",
       "3  1076863    1277178      10000        10000            10000   36 months   \n",
       "4  1075269    1311441       5000         5000             5000   36 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade          ...          sub_grade_num  \\\n",
       "0     10.65       162.87     B        B2          ...                    0.4   \n",
       "1     15.27        59.83     C        C4          ...                    0.8   \n",
       "2     15.96        84.33     C        C5          ...                    1.0   \n",
       "3     13.49       339.31     C        C1          ...                    0.2   \n",
       "4      7.90       156.46     A        A4          ...                    0.8   \n",
       "\n",
       "  delinq_2yrs_zero pub_rec_zero  collections_12_mths_zero short_emp  \\\n",
       "0              1.0          1.0                       1.0         0   \n",
       "1              1.0          1.0                       1.0         1   \n",
       "2              1.0          1.0                       1.0         0   \n",
       "3              1.0          1.0                       1.0         0   \n",
       "4              1.0          1.0                       1.0         0   \n",
       "\n",
       "  payment_inc_ratio          final_d last_delinq_none last_record_none  \\\n",
       "0           8.14350  20141201T000000                1                1   \n",
       "1           2.39320  20161201T000000                1                1   \n",
       "2           8.25955  20141201T000000                1                1   \n",
       "3           8.27585  20141201T000000                0                1   \n",
       "4           5.21533  20141201T000000                1                1   \n",
       "\n",
       "  last_major_derog_none  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the target and the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_loans =  1 => safe\n",
    "# safe_loans = -1 => risky\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>term</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>safe_loans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>60 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3 years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grade        term home_ownership emp_length  safe_loans\n",
       "0     B   36 months           RENT  10+ years           1\n",
       "1     C   60 months           RENT   < 1 year          -1\n",
       "2     C   36 months           RENT  10+ years           1\n",
       "3     C   36 months           RENT  10+ years           1\n",
       "4     A   36 months           RENT    3 years           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\Classification\\Project 7\\data\\train-idx.json\") as f:\n",
    "    train_idx=json.load(f)\n",
    "with open(r\"D:\\Classification\\Project 7\\data\\test-idx.json\") as f:\n",
    "    test_idx=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = loans.iloc[train_idx].reset_index()\n",
    "test_data = loans.iloc[test_idx].reset_index()\n",
    "train_data = train_data.drop('index', 1)\n",
    "test_data = test_data.drop('index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted error definition\n",
    "\n",
    "Predictions $\\hat{y}_1,…,\\hat{y}_n$\n",
    "\n",
    "Target $y_1,…,y_n$\n",
    "\n",
    "Data point weights $α_1,…,α_n$\n",
    "\n",
    "Then the **weighted error** is defined by:\n",
    "\n",
    "$$E(α,\\hat{\\textbf{y}}) = \\frac{\\sum_{i=1}^{n}α_i*I[y_i \\neq \\hat{y_i}]}{\\sum_{i=1}^{n}α_i}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    '''\n",
    "    labels_in_node: y_1,…,y_n\n",
    "    data_weights: Data point weights α_1,…,α_n\n",
    "    Return: the tuple (weight, class_label) representing the lower of the two weights. \n",
    "    If the two weights are identical, return (weighted_mistakes_all_positive,+1) \n",
    "    '''\n",
    "    # Sum the weights of all entries with label +1\n",
    "    #print(labels_in_node)\n",
    "    #print('---------xxx--------')\n",
    "    #print(len(data_weights))\n",
    "    total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Sum the weights of all entries with label -1\n",
    "    total_weight_negative = sum(data_weights[labels_in_node == -1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    return min((weighted_mistakes_all_positive,+1),(weighted_mistakes_all_negative,-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "    \n",
    "    # These variables will keep track of the best feature and the corresponding error\n",
    "    best_feature = None\n",
    "    best_error = float('+inf') \n",
    "    \n",
    "    num_points = float(len(data))\n",
    "\n",
    "    # Looping through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        left_data_weights = data_weights[data[feature] == 0]\n",
    "        right_data_weights = data_weights[data[feature] == 1]\n",
    "                    \n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(left_split[target], left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(right_split[target], right_data_weights)\n",
    "        \n",
    "        error = (left_weighted_mistakes + right_weighted_mistakes)/sum(data_weights)\n",
    "        \n",
    "        # If this is the best error we have found so far, store the feature and the error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    \n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    leaf['prediction'] = best_class\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    target_values = data[target]\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "    # Stopping condition 1. Error is 0.\n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print(\"Stopping condition 1 reached.\")                \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. No more features.\n",
    "    if remaining_features == []:\n",
    "        print(\"Stopping condition 2 reached.\")                \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Stopping condition 3. Limit tree depth.\n",
    "    if current_depth > max_depth:\n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # If all the datapoints are the same, splitting_feature will be None. Create a leaf\n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "        \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[data[splitting_feature] == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature] == 1]\n",
    "    \n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "              splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with a weighted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print(\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # Split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print(\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    prediction = data.apply(lambda x: classify(tree, x),axis=1)\n",
    "    return (prediction != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights\n",
    "example_data_weights = np.concatenate((np.ones(10),np.zeros(len(train_data) - 20),np.ones(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [i for i in train_data.columns]\n",
    "features.remove('safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_RENT. (20514, 16710)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20514 data points).\n",
      "Split on feature grade_F. (19613, 901)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (19613 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (901 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16710 data points).\n",
      "Split on feature grade_D. (13315, 3395)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13315 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3395 data points).\n",
      "Stopping condition 1 reached.\n"
     ]
    }
   ],
   "source": [
    "# Train a weighted decision tree model.\n",
    "small_data_decision_tree_subset_20 = weighted_decision_tree_create(train_data, features, target,\n",
    "                         example_data_weights, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_20 = train_data.head(10).append(train_data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree_subset_20, subset_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48124865678057166"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree_subset_20, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The points with higher weights are the ones that are more important during the training process of the weighted decision tree.\n",
    "\n",
    "* The points with zero weights are basically ignored during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Adaboost (on decision stumps)\n",
    "$$\n",
    "\\hat{w_t}=\\frac{1}{2}ln\\Big(\\frac{1−E(α,\\hat{\\textbf{y}})}{E(α,\\hat{\\textbf{y}})}\\Big)\\\\\n",
    "\\\\\n",
    "$$\n",
    "$$\n",
    "\\alpha_j \\gets \\begin{cases} \\alpha_j \\exp{(-\\hat{w}_t)} & \\text{ if }f_t(x_j) = y_j\\\\\\alpha_j \\exp{(\\hat{w}_t)} & \\text{ if }f_t(x_j) \\neq y_j \\end{cases}\\\\\n",
    "$$\n",
    "Normalize weights:\n",
    "$$\n",
    "\\alpha_j \\gets \\dfrac{\\alpha_j}{\\sum_{i=1}^{N}{\\alpha_i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # start with unweighted data\n",
    "    alpha = np.ones(len(data))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in range(num_tree_stumps):\n",
    "        print('=====================================================')\n",
    "        print('Adaboost Iteration %d' % t)\n",
    "        print('=====================================================')       \n",
    "        # Learn a weighted decision tree stump. Use max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x),axis=1)\n",
    "        \n",
    "        # Produce a Boolean array indicating whether\n",
    "        # each data point was correctly classified\n",
    "        is_correct = predictions == target_values\n",
    "        is_wrong   = predictions != target_values\n",
    "\n",
    "        weighted_error = weighted_error = sum(alpha[is_wrong])/sum(alpha)\n",
    "        \n",
    "        # Compute model coefficient using weighted error\n",
    "        weight = 0.5*math.log((1-weighted_error)/weighted_error)\n",
    "        weights.append(weight)\n",
    "        \n",
    "        # Adjust weights on data point\n",
    "        adjustment = is_correct.apply(lambda is_correct : math.exp(-weight) if is_correct else math.exp(weight))\n",
    "        \n",
    "        # Scale alpha by multiplying by adjustment\n",
    "        # Then normalize data points weights\n",
    "        alpha = alpha*adjustment\n",
    "        alpha= alpha/sum(alpha)\n",
    "    \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a boosted ensemble of 10 stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions\n",
    "$$\\displaystyle \\hat{y} = \\mathrm{sign}\\left(\\sum_{t=1}^T \\hat{w}_t f_t(x)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = np.zeros(len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x),axis=1)\n",
    "        \n",
    "        # Accumulate predictions on scaores array\n",
    "        scores += (stump_weights[i] * predictions)\n",
    "        \n",
    "    return scores.apply(lambda score : +1 if score > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15802933659263743,\n",
       " 0.1768236329364191,\n",
       " 0.09311888971129693,\n",
       " 0.07288885525840554,\n",
       " 0.06706306914118143,\n",
       " 0.06456916961644447,\n",
       " 0.05456055779178564,\n",
       " 0.04351093673362621,\n",
       " 0.02898871150041245,\n",
       " 0.01933343817072769]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_adaboost(stump_weights, tree_stumps, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = float(sum(test_data[target] == predictions))/len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6220379146919431"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 10\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 11\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 12\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 13\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 14\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 15\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_4 years. (34593, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34593 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2631 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 16\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 17\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_2 years. (33652, 3572)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33652 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3572 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 18\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 19\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_10+ years. (26901, 10323)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26901 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10323 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 20\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 21\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_G. (36788, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36788 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (436 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 22\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_3 years. (34099, 3125)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34099 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3125 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 23\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 24\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_OWN. (34149, 3075)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34149 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3075 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 25\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_G. (36788, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36788 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (436 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 26\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature emp_length_4 years. (34593, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34593 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2631 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 27\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_G. (36788, 436)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36788 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (436 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 28\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 29\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_C. (27812, 9412)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27812 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9412 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, \n",
    "                                 features, target, num_tree_stumps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing training error at the end of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.4216365785514722\n",
      "Iteration 2, training error = 0.43343004513217276\n",
      "Iteration 3, training error = 0.4000376101439931\n",
      "Iteration 4, training error = 0.4000376101439931\n",
      "Iteration 5, training error = 0.3847249086610789\n",
      "Iteration 6, training error = 0.3846174511068128\n",
      "Iteration 7, training error = 0.3827638082957232\n",
      "Iteration 8, training error = 0.3846174511068128\n",
      "Iteration 9, training error = 0.3827638082957232\n",
      "Iteration 10, training error = 0.38144745325596385\n",
      "Iteration 11, training error = 0.38144745325596385\n",
      "Iteration 12, training error = 0.38144745325596385\n",
      "Iteration 13, training error = 0.38144745325596385\n",
      "Iteration 14, training error = 0.38144745325596385\n",
      "Iteration 15, training error = 0.38144745325596385\n",
      "Iteration 16, training error = 0.3814205888673974\n",
      "Iteration 17, training error = 0.3814205888673974\n",
      "Iteration 18, training error = 0.3816355039759295\n",
      "Iteration 19, training error = 0.3816355039759295\n",
      "Iteration 20, training error = 0.3816355039759295\n",
      "Iteration 21, training error = 0.3814205888673974\n",
      "Iteration 22, training error = 0.382441435632925\n",
      "Iteration 23, training error = 0.3814205888673974\n",
      "Iteration 24, training error = 0.3824145712443585\n",
      "Iteration 25, training error = 0.3814205888673974\n",
      "Iteration 26, training error = 0.3824145712443585\n",
      "Iteration 27, training error = 0.3813668600902643\n",
      "Iteration 28, training error = 0.38155491081022996\n",
      "Iteration 29, training error = 0.3818772834730282\n",
      "Iteration 30, training error = 0.38182355469589513\n"
     ]
    }
   ],
   "source": [
    "error_all = []\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    accuracy = float(sum(train_data[target] == predictions))/len(train_data)\n",
    "    error = 1.0 - accuracy\n",
    "    error_all.append(error)\n",
    "    print(\"Iteration %s, training error = %s\" % (n, error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de2b8b2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, test error = 0.4233089185695821\n",
      "Iteration 2, test error = 0.4284791038345541\n",
      "Iteration 3, test error = 0.3981042654028436\n",
      "Iteration 4, test error = 0.3981042654028436\n",
      "Iteration 5, test error = 0.37990090478242133\n",
      "Iteration 6, test error = 0.38000861697544164\n",
      "Iteration 7, test error = 0.37925463162429984\n",
      "Iteration 8, test error = 0.38000861697544164\n",
      "Iteration 9, test error = 0.37925463162429984\n",
      "Iteration 10, test error = 0.37796208530805686\n",
      "Iteration 11, test error = 0.37796208530805686\n",
      "Iteration 12, test error = 0.37796208530805686\n",
      "Iteration 13, test error = 0.37796208530805686\n",
      "Iteration 14, test error = 0.37796208530805686\n",
      "Iteration 15, test error = 0.37796208530805686\n",
      "Iteration 16, test error = 0.37817750969409736\n",
      "Iteration 17, test error = 0.37817750969409736\n",
      "Iteration 18, test error = 0.37785437311503667\n",
      "Iteration 19, test error = 0.37785437311503667\n",
      "Iteration 20, test error = 0.37785437311503667\n",
      "Iteration 21, test error = 0.37817750969409736\n",
      "Iteration 22, test error = 0.37731581214993537\n",
      "Iteration 23, test error = 0.37817750969409736\n",
      "Iteration 24, test error = 0.3772080999569152\n",
      "Iteration 25, test error = 0.37817750969409736\n",
      "Iteration 26, test error = 0.3772080999569152\n",
      "Iteration 27, test error = 0.37860835846617835\n",
      "Iteration 28, test error = 0.37817750969409736\n",
      "Iteration 29, test error = 0.37699267557087457\n",
      "Iteration 30, test error = 0.3774235243429557\n"
     ]
    }
   ],
   "source": [
    "test_error_all = []\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], test_data)\n",
    "    accuracy = float(sum(test_data[target] == predictions))/len(test_data)\n",
    "    error = 1.0 - accuracy\n",
    "    test_error_all.append(error)\n",
    "    print(\"Iteration %s, test error = %s\" % (n, test_error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de2c842668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.plot(range(1,31), test_error_all, '-', linewidth=4.0, label='Test error')\n",
    "\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
