# Ridge regression and using 10-fold CV method to tune L2-penalty

Libaries used: numpy, pandas, matplotlib, scikit

Tools used: Jupyter Notebook

* Part 1:

In this, I trained a polynomial function of sq_feet to predict the price of the house. First, I compared the coefficients for the low penalty model and high penalty model.

Result: Higher the penalty steeper the graph, or in words, the model becomes biased and the value of the coefficients becomes small.

* Part 2:

In this part, I used 10-fold cross validation method to get the best penalty for the model.

* Part 3:
##### Implementation of ridge regression from scratch using gradient descent.

[Other Machine Learning Projects](https://github.com/gov-vj/Machine-Learning-Projects)
